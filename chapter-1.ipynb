{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1\n",
    "### 1.1.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the law of total probability (LOTP) the marginal density of *y* is defined as the weighted average of the conditional densities:\n",
    "$$p(y) = \\sum_{\\theta}{p(y|\\theta) * p(\\theta)}$$\n",
    "In the present examples with two possible values for theta, this is\n",
    "$$p(y) = p(y|\\theta_1)*p(\\theta_1)+p(y|\\theta_2)*p(\\theta_2)$$\n",
    "Since both are normal and the thetas a equally likely unconditionally, the equation takes the following form:\n",
    "$$p(y) = \\frac{1}{2}*(\\mathcal{N}(y|0, 2^2) + \\mathcal{N}(y|1, 2^2))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = np.array([.5, .5]) # prior on thetas\n",
    "mus = [0, 1]\n",
    "x = np.linspace(-4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9:\n",
    "\n",
    "## Simulate subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_subs():\n",
    "    t_max = 420\n",
    "    subs = []\n",
    "    t = 0\n",
    "    while True:\n",
    "        sub = t + np.random.exponential(10)\n",
    "        if sub > t_max:\n",
    "            break\n",
    "        subs.append(sub)\n",
    "        t = sub\n",
    "    n_subs = len(subs)\n",
    "    return subs, n_subs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate doctors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_docs(subs):\n",
    "    doc_t = np.zeros(3)\n",
    "    wt = []\n",
    "    for s in subs:\n",
    "        duration = np.random.uniform(5, 20)\n",
    "        if any(doc_t < s):\n",
    "            wt.append(0)\n",
    "            doc_t[np.argmin(doc_t)] = s + duration\n",
    "        else:\n",
    "            wt.append(doc_t.min() - s)\n",
    "            doc_t[np.argmin(doc_t)] += duration\n",
    "    wt_nonzero  = np.array([x for x in wt if not x == 0])\n",
    "    avg_wait = wt_nonzero.mean() if len(wt_nonzero) > 0 else 0\n",
    "    n_hadtowait = wt_nonzero.size\n",
    "    closing_delay = np.max([0, doc_t.max() - 420])\n",
    "    return n_hadtowait, avg_wait, closing_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1415.45it/s]\n"
     ]
    }
   ],
   "source": [
    "runs = 10000\n",
    "n_subs, n_hadtowait, avg_wait, closing_delay = [\n",
    "    np.empty(shape=(runs,), dtype=np.float) for _ in range(4)\n",
    "]\n",
    "for r in tqdm(range(runs)):\n",
    "    subs, n_subs[r] = simulate_subs()\n",
    "    n_hadtowait[r], avg_wait[r], closing_delay[r] = simulate_docs(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(data):\n",
    "    return [np.percentile(data, x) for x in [25, 50, 75]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects: 38.00, 42.00, 46.00\n",
      "Average waiting time: 2.54, 3.77, 5.09\n",
      "Number of waiting: 3.00, 5.00, 8.00\n",
      "Closing delay 0.00, 5.94, 11.34\n"
     ]
    }
   ],
   "source": [
    "print('Number of subjects: {:.2f}, {:.2f}, {:.2f}'.format(*get_stats(all_n_subs)))\n",
    "print('Average waiting time: {:.2f}, {:.2f}, {:.2f}'.format(*get_stats(all_avg_wait)))\n",
    "print('Number of waiting: {:.2f}, {:.2f}, {:.2f}'.format(*get_stats(all_n_hadtowait)))\n",
    "print('Closing delay {:.2f}, {:.2f}, {:.2f}'.format(*get_stats(all_closing_delay)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import gamma, poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatal = np.array([24, 25, 31, 31, 22, 21, 26, 20, 16, 22])\n",
    "deaths = np.array([734, 516, 754, 877, 814, 362, 764, 809, 223, 1066])\n",
    "deathrate = np.array([19, 12, 15, 16, 14, 6, 13, 13, 3, 15]) / 100\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'fatal': fatal,\n",
    "        'deaths': deaths,\n",
    "        'deathrate': deathrate\n",
    "    },\n",
    "    index=np.arange(1976, 1986)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Jeffrey's prior leads to the improper gamma(1/2, 0) distribution\n",
    "Since it's conjugate, we can still compute the proper posterior.\n",
    "To condition on the date, we add the number of years to $\\beta$ and the total number to $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_alpha = 1/2\n",
    "prior_beta = 0\n",
    "n_years = df.shape[0]\n",
    "total_fatal = df.fatal.sum()\n",
    "posterior_alpha = prior_alpha + total_fatal\n",
    "posterior_beta = prior_beta + n_years\n",
    "\n",
    "posterior = gamma(a=posterior_alpha, scale=1/posterior_beta)#fuck scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14. 34.]\n"
     ]
    }
   ],
   "source": [
    "theta_samples = posterior.rvs(100000)\n",
    "fatal_samples = poisson(theta_samples).rvs()\n",
    "pred_interval = np.percentile(fatal_samples, [2.5, 97.5]).round(4)\n",
    "print(pred_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13b\n",
    "miles = 1e8 * (df.deaths / df.deathrate)\n",
    "total_miles = miles.sum()\n",
    "posterior_alpha = prior_alpha + total_fatal\n",
    "posterior_beta = prior_beta + total_miles\n",
    "posterior = gamma(a=posterior_alpha, scale=1/posterior_beta)\n",
    "theta_samples = posterior.rvs(100000)\n",
    "miles_1986 = 8e11\n",
    "fatal_samples = poisson(miles_1986 * theta_samples).rvs()\n",
    "pred_interval = np.percentile(fatal_samples, [2.5, 97.5]).round(4)\n",
    "pred_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) and d) are \"completely analogous\" (shoutout to Joe Blitzstein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
